{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import dataloader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "n_epochs = 200 \n",
    "dataset_name = 'facade'\n",
    "batch_size = 1\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "decay_epoch = 100\n",
    "sample_interval = 50\n",
    "n_cpu = 8\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "channels = 3\n",
    "checkpoint_interval = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\",exist_ok=True)\n",
    "os.makedirs(\"saved_model\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data,0.0,0.2)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data,1.0,0.2)\n",
    "        torch.nn.init.constant_(m.bias.data,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetDown(nn.Module):\n",
    "    def __init__(self,in_size,out_size,normalize=True,dropout=0.0):\n",
    "        super(UnetDown,self).__init__()\n",
    "        layers = [nn.Conv2d(in_size,out_size,4,2,1,bias = False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return model(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetUp(nn.Module):\n",
    "    def __init__(self,in_size,out_size,dropout=0.0):\n",
    "        super(UnetUp,self).__init__()\n",
    "        \n",
    "        layers = [nn.ConvTranspose2d(in_size,out_size,4,2,1,bias=False),\n",
    "                    nn.InstanceNorm2d(out_size),\n",
    "                     nn.ReLU(inplace=True)]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        def forward(self,x,skip_input):\n",
    "            x =  self.model(x)\n",
    "            x = torch.cat((x,skip_input),1)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorUnet(nn.Module):\n",
    "    def __init__(self,in_channel = 3,out_channel = 3):\n",
    "        super(GeneratorUnet,self).__init__()\n",
    "            \n",
    "        self.down1 = UnetDown(in_channel,64,normalize=False)\n",
    "        self.down2 = UnetDown(64,128)\n",
    "        self.down3 = UnetDown(128,256)\n",
    "        self.down4 = UnetDown(256,512,dropout=0.5)\n",
    "        self.down5 = UnetDown(512,512,dropout = 0.5)\n",
    "        self.down6 = UnetDown(512,512,dropout=0.5)\n",
    "        self.down7 = UnetDown(512,512,dropout=0.5)\n",
    "        self.down8 = UnetDown(512,512,dropout=0.5,normalize=False)\n",
    "            \n",
    "        self.up1 = UnetUp(512,512,dropout=0.5)\n",
    "        self.up2 = UnetUp(1024,512,dropout=0.5)\n",
    "        self.up3 = UnetUp(1024,512,dropout=0.5)\n",
    "        self.up4 = UnetUp(1024,512,dropout=0.5)\n",
    "        self.up5 = UnetUp(1024,256)\n",
    "        self.up6 = UnetUp(512,128)\n",
    "        self.up7 = UnetUp(256,64)\n",
    "            \n",
    "        self.final = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor = 2),\n",
    "                            nn.ZeroPad2d((1,0,1,0)),\n",
    "                            nn.Conv2d(128,out_channel,4,padding = 1),\n",
    "                            nn.Tanh())\n",
    "            \n",
    "            \n",
    "        def forward(self,x):\n",
    "            d1 = self.down1(x)\n",
    "            d2 = self.down2(d1)\n",
    "            d3 = self.down3(d2)\n",
    "            d4 = self.down4(d3)\n",
    "            d5 = self.down5(d4)\n",
    "            d6 = self.down6(d5)\n",
    "            d7 = self.down7(d6)\n",
    "            d8 = self.down8(d7)\n",
    "                \n",
    "            u1 = self.up1(d8,d7)\n",
    "            u2 = self.up2(u1,d6)\n",
    "            u3 = self.up3(u2,d5)\n",
    "            u4 = self.up4(u3,d4)\n",
    "            u5 = self.up5(u4,d3)\n",
    "            u6 = self.up6(u5,d2)\n",
    "            u7 = self.up7(u6,d1)\n",
    "                \n",
    "            return self.final(u7)\n",
    "                \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_fil,out_fil,normalize = True):\n",
    "            layers = [nn.Conv2d(in_fil,out_fil,4,2,1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_fil))\n",
    "            layers.append(nn.LeakyReLU(inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(*discriminator_block(in_channels*2,64,normalize=False),\n",
    "                                  *discriminator_block(64,128),\n",
    "                                  *discriminator_block(128,256),\n",
    "                                    *discriminator_block(256,512),\n",
    "                                  nn.ZeroPad2d((1,0,1,0)),\n",
    "                                    nn.Conv2d(512,1,4,1,bias=False))\n",
    "        \n",
    "        \n",
    "    def forward(self,img_A,img_B):\n",
    "        img_input = torch.cat((img_A,img_B),1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def ImageDataset(Dataset):\n",
    "    def __init__(self,root,transform=None,mode = \"train\"):\n",
    "        self.transorm = transforms.Compose(transforms_)\n",
    "        \n",
    "        self.files = sorted(glob.glob(os.path.join(root,mode) + \"/*.*\"))\n",
    "        if mode == \"train\":\n",
    "            self.files.extend(sorted(glob.glob(os.path.join(root,\"test\")+\"/*.*\")))\n",
    "            \n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        w,h = img.size\n",
    "        img_A = img.crop((0,0,w / 2 ,h))\n",
    "        img_B = img.crop((w/2,0,w,h))\n",
    "        \n",
    "        if np.random.random() < 0.5:\n",
    "            img_A = Image.fromarray(np.array(img_A)[:, ::-1, :], \"RGB\")\n",
    "            img_B = Image.fromarray(np.array(img_B)[:, ::-1, :], \"RGB\")\n",
    "            \n",
    "            \n",
    "        img_A = self.transform(img_A)\n",
    "        img_B = self.transform(img_B)\n",
    "        \n",
    "        return {\"A\":img_A,\"B\":img_B}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "crieterion_GAN = torch.nn.MSELoss()\n",
    "crieterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "lambda_pixel = 100\n",
    "patch = (1,img_height// 2 ** 4,img_width // 2 ** 4)\n",
    "\n",
    "generator = GeneratorUnet()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    crieterion_GAN.cuda()\n",
    "    crieterion_pixelwise.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch != 0:\n",
    "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (dataset_name, epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (dataset_name,epoch)))\n",
    "else:\n",
    "    generator.apply(weight_init_normal)\n",
    "    discriminator.apply(weight_init_normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(),lr=lr,betas = (b1,b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(),lr=lr,betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
